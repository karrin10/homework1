# homework1
Kathleen Arrington
801060877
ECGR 4105
9/13/23

1. Higher learning rates, such as 0.1, converge much faster but sometimes can overshoot the solution which creates instability. Lower learning rates, such as 0.001, converge much slower but have a higher chance of finding the solution with stable convergence. However, the choice between the two learning rates should have a balanced effect between convergence speed and stability. With this assignment we can compare and observe the difference between the learning rates and how they affect the loss curves in the plots. The code will perform linear regression with gradient descent for each explanatory variable separately, observe the learning rates, and help us determine the variable with the lowest loss.

2. This code will run linear regression with gradient descent using all of the three explanatory variables, observe the learning rates, report the best linear plot, and plot the loss over iterations for each learning rate, and predict the values of Y for the new values of X1, X2, and X3. And the choice of the best learning rate is decided on the convergence behavior observed in the loss plot that is created.
